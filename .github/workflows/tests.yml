name: Tests

on:
  # https://docs.github.com/en/webhooks-and-events/webhooks/webhook-events-and-payloads#push
  push:
    branches:
      - main
      - feature/**
      - '[0-9].*.x'  # e.g., 4.14.x
      - '[0-9][0-9].*.x'  # e.g., 23.3.x

  # https://docs.github.com/en/webhooks-and-events/webhooks/webhook-events-and-payloads#pull_request
  pull_request:

  # https://docs.github.com/en/webhooks-and-events/webhooks/webhook-events-and-payloads#workflow_dispatch
  workflow_dispatch:

concurrency:
  # Concurrency group that uses the workflow name and PR number if available
  # or commit SHA as a fallback. If a new build is triggered under that
  # concurrency group while a previous build is running it will be canceled.
  # Repeated pushes to a PR will cancel all previous builds, while multiple
  # merges to main will not cancel.
  group: ${{ github.workflow }}-${{ github.event.pull_request.number || github.sha }}
  cancel-in-progress: true

jobs:
  # detect whether any code changes are included in this PR
  changes:
    runs-on: ubuntu-latest
    permissions:
      # necessary to detect changes
      # https://github.com/dorny/paths-filter#supported-workflows
      pull-requests: read
    outputs:
      code: ${{ steps.filter.outputs.code }}
    steps:
      - uses: actions/checkout@v4
        # dorny/paths-filter needs git clone for push events
        # https://github.com/dorny/paths-filter#supported-workflows
        if: github.event_name != 'pull_request'

      - uses: dorny/paths-filter@v2.11.1
        id: filter
        with:
          filters: |
            code:
              - 'conda/**'
              - 'conda_env/**'
              - 'tests/**'
              - '*.py'
              - 'recipe/**'
              - '.github/workflows/tests.yml'
              - 'dev/**/setup.*'
              - 'dev/**/integration.*'
              - 'dev/**/unit.*'
              - 'dev/**/qemu.*'

  # windows test suite
  windows:
    # only run test suite if there are code changes
    needs: changes
    if: false && needs.changes.outputs.code == 'true'

    runs-on: windows-latest
    strategy:
      fail-fast: false
      matrix:
        # test lower version (w/ defaults) and upper version (w/ defaults and conda-forge)
        python-version: ['3.8', '3.11']
        default-channel: [defaults, conda-forge]
        test-type: [unit, integration]
        test-group: [1, 2, 3]
        exclude:
          - python-version: '3.8'
            default-channel: conda-forge
          - test-type: unit
            test-group: 3
    env:
      ALLURE_DIR: ${{ github.workspace }}\allure-results
      PYTEST_MARKER: ${{ matrix.test-type == 'unit' && 'not integration' || 'integration' }}
      PYTEST_NUMPROCESSES: 0
      PYTEST_SPLITS: ${{ matrix.test-type == 'unit' && 2 || 3 }}

    steps:
      - name: Checkout Source
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Hash + Timestamp
        run: echo "HASH=${{ runner.os }}-${{ runner.arch }}-Py${{ matrix.python-version }}-${{ matrix.default-channel }}-${{ matrix.test-type }}-${{ matrix.test-group }}-$(date -u "+%Y%m")" >> $GITHUB_ENV
        shell: bash

      - name: Cache Conda
        uses: actions/cache@v3
        with:
          path: ~/conda_pkgs_dir
          key: cache-${{ env.HASH }}

      - name: Setup Miniconda
        uses: conda-incubator/setup-miniconda@v2
        with:
          condarc-file: .github\condarc-${{ matrix.default-channel }}
          python-version: ${{ matrix.python-version }}
          run-post: false  # skip post cleanup

      - name: Setup Environment
        run: conda install --quiet --yes
            --file tests\requirements.txt
            --file tests\requirements-s3.txt
            --file tests\requirements-ci.txt
            --file tests\requirements-${{ runner.os }}.txt
          && pip install -e .

      - name: Show Info
        run: |
          conda info --verbose
          conda list --show-channel-urls

      - name: Run Tests
        run: pytest
          --alluredir="${{ env.ALLURE_DIR }}"
          --basetemp="${{ runner.temp }}\${{ matrix.test-type }}"
          --cov=conda
          --durations-path="tools\durations\${{ runner.os }}.json"
          --group=${{ matrix.test-group }}
          --splits=${{ env.PYTEST_SPLITS }}
          -m "${{ env.PYTEST_MARKER }}"
          -n "${{ env.PYTEST_NUMPROCESSES }}"

      - name: Upload Coverage
        uses: codecov/codecov-action@v3
        with:
          flags: ${{ runner.os }},${{ runner.arch }},${{ matrix.python-version }},${{ matrix.test-type }}

      - name: Upload Test Results
        if: '!cancelled()'
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ env.HASH }}
          path: |
            .coverage
            tools\durations\${{ runner.os }}.json
            test-report.xml
          retention-days: 1  # temporary, combined in aggregate below

      - name: Tar Allure
        if: '!cancelled()'
        run: tar -zcf "${{ env.ALLURE_DIR }}.tar.gz" "${{ env.ALLURE_DIR }}"
        # windows-2019/powershell ships with GNU tar 1.28 which struggles with Windows paths
        # window-2019/cmd ships with bsdtar 3.5.2 which doesn't have this problem
        shell: cmd

      - name: Upload Allure
        if: '!cancelled()'
        uses: actions/upload-artifact@v3
        with:
          name: allure-${{ env.HASH }}
          path: ${{ env.ALLURE_DIR }}

  # linux test suite
  linux:
    # only run test suite if there are code changes
    needs: changes
    if: false && needs.changes.outputs.code == 'true'

    runs-on: ubuntu-latest
    defaults:
      run:
        # https://github.com/conda-incubator/setup-miniconda#use-a-default-shell
        shell: bash -l {0}
    strategy:
      fail-fast: false
      matrix:
        # test all lower versions (w/ defaults) and upper version (w/ defaults and conda-forge)
        python-version: ['3.8', '3.9', '3.10', '3.11']
        default-channel: [defaults, conda-forge]
        test-type: [unit, integration]
        test-group: [1, 2, 3]
        exclude:
          - python-version: '3.8'
            default-channel: conda-forge
          - python-version: '3.9'
            default-channel: conda-forge
          - python-version: '3.10'
            default-channel: conda-forge
          - test-type: unit
            test-group: 3
    env:
      ALLURE_DIR: ${{ github.workspace }}/allure-results
      PYTEST_MARKER: ${{ matrix.test-type == 'unit' && 'not integration' || 'integration' }}
      PYTEST_NUMPROCESSES: 0
      PYTEST_SPLITS: ${{ matrix.test-type == 'unit' && 2 || 3 }}

    steps:
      - name: Checkout Source
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Hash + Timestamp
        run: echo "HASH=${{ runner.os }}-${{ runner.arch }}-Py${{ matrix.python-version }}-${{ matrix.default-channel }}-${{ matrix.test-type }}-${{ matrix.test-group }}-$(date -u "+%Y%m")" >> $GITHUB_ENV
        shell: bash

      - name: Cache Conda
        uses: actions/cache@v3
        with:
          path: ~/conda_pkgs_dir
          key: cache-${{ env.HASH }}

      - name: Setup Miniconda
        uses: conda-incubator/setup-miniconda@v2
        with:
          condarc-file: .github/condarc-${{ matrix.default-channel }}
          python-version: ${{ matrix.python-version }}
          run-post: false  # skip post cleanup

      - name: Setup Environment
        run: conda install --quiet --yes
            --file tests/requirements.txt
            --file tests/requirements-s3.txt
            --file tests/requirements-ci.txt
          && pip install -e .

      - name: Show Info
        run: |
          conda info --verbose
          conda list --show-channel-urls

      - name: Run Tests
        run: pytest
          --alluredir="${{ env.ALLURE_DIR }}"
          --basetemp="${{ runner.temp }}/${{ matrix.test-type }}"
          --cov=conda
          --durations-path=tools/durations/${{ runner.os }}.json
          --group=${{ matrix.test-group }}
          --splits=${{ env.PYTEST_SPLITS }}
          -m "${{ env.PYTEST_MARKER }}"
          -n "${{ env.PYTEST_NUMPROCESSES }}"

      - name: Upload Coverage
        uses: codecov/codecov-action@v3
        with:
          flags: ${{ runner.os }},${{ runner.arch }},${{ matrix.python-version }},${{ matrix.test-type }}

      - name: Upload Test Results
        if: '!cancelled()'
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ env.HASH }}
          path: |
            .coverage
            tools/durations/${{ runner.os }}.json
            test-report.xml
          retention-days: 1  # temporary, combined in aggregate below

      - name: Tar Allure
        if: '!cancelled()'
        run: tar -zcf "${{ env.ALLURE_DIR }}.tar.gz" "${{ env.ALLURE_DIR }}"

      - name: Upload Allure
        if: '!cancelled()'
        uses: actions/upload-artifact@v3
        with:
          name: allure-${{ env.HASH }}
          path: ${{ env.ALLURE_DIR }}

  # linux-qemu test suite
  linux-qemu:
    # only run test suite if there are code changes
    needs: changes
    if: needs.changes.outputs.code == 'true'

    # Run one single fast test per docker+qemu emulated linux platform to test that
    # test execution is possible there (container+tools+dependencies work). Can be
    # changed / extended to run specific tests in case there are platform related
    # things to test. Running more tests is time consuming due to emulation
    # (factor 2-10x slower).
    runs-on: ubuntu-latest
    defaults:
      run:
        # https://github.com/conda-incubator/setup-miniconda#use-a-default-shell
        shell: bash -l {0}
    strategy:
      fail-fast: false
      matrix:
        python-version: ['3.11']
        default-channel: [defaults, conda-forge]
        platform: [arm64, ppc64le]
    container:
      image: debian:11
      options: --platform linux/${{ matrix.platform }}

    steps:
      # - name: Checkout Source
      #   uses: actions/checkout@v4
      #   with:
      #     fetch-depth: 0

      # - name: Hash + Timestamp
      #   run: echo "HASH=${{ runner.os }}-${{ runner.arch }}-Py${{ matrix.python-version }}-${{ matrix.default-channel }}-${{ matrix.platform }}-$(date -u "+%Y%m")" >> $GITHUB_ENV
      #   shell: bash

      # - name: Cache Conda
      #   uses: actions/cache@v3
      #   with:
      #     path: ~/conda_pkgs_dir
      #     key: cache-${{ env.HASH }}

      - name: Setup Miniconda
        uses: conda-incubator/setup-miniconda@v2
        with:
          condarc-file: .github/condarc-${{ matrix.default-channel }}
          python-version: ${{ matrix.python-version }}
          run-post: false  # skip post cleanup

      # - name: Setup Environment
      #   run: conda install --quiet --yes
      #       --file tests/requirements.txt
      #       --file tests/requirements-ci.txt
      #     && pip install -e .

      - name: Show Info
        run: |
          conda info --verbose
          conda list --show-channel-urls

      # - name: Run Tests
      #   run: pytest
      #     --basetemp="${{ runner.temp }}/${{ matrix.test-type }}"
      #     tests/test_api.py::test_DepsModifier_contract

  # macos test suite
  macos:
    # only run test suite if there are code changes
    needs: changes
    if: false && needs.changes.outputs.code == 'true'

    runs-on: macos-latest
    defaults:
      run:
        # https://github.com/conda-incubator/setup-miniconda#use-a-default-shell
        shell: bash -l {0}
    strategy:
      fail-fast: false
      matrix:
        # test defaults with integration tests and conda-forge with unit tests
        python-version: ['3.9']
        default-channel: [defaults, conda-forge]
        test-type: [unit, integration]
        test-group: [1, 2, 3]
        exclude:
          - default-channel: conda-forge
            test-type: integration
          - default-channel: defaults
            test-type: unit
          - test-type: unit
            test-group: 3
    env:
      ALLURE_DIR: ${{ github.workspace }}/allure-results
      PYTEST_MARKER: ${{ matrix.test-type == 'unit' && 'not integration' || 'integration' }}
      PYTEST_NUMPROCESSES: 0
      PYTEST_SPLITS: ${{ matrix.test-type == 'unit' && 2 || 3 }}

    steps:
      - name: Checkout Source
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Hash + Timestamp
        run: echo "HASH=${{ runner.os }}-${{ runner.arch }}-Py${{ matrix.python-version }}-${{ matrix.default-channel }}-${{ matrix.test-type }}-${{ matrix.test-group }}-$(date -u "+%Y%m")" >> $GITHUB_ENV
        shell: bash

      - name: Cache Conda
        uses: actions/cache@v3
        with:
          path: ~/conda_pkgs_dir
          key: cache-${{ env.HASH }}

      - name: Setup Miniconda
        uses: conda-incubator/setup-miniconda@v2
        with:
          condarc-file: .github/condarc-${{ matrix.default-channel }}
          python-version: ${{ matrix.python-version }}
          run-post: false  # skip post cleanup

      - name: Setup Environment
        run: conda install --quiet --yes
            --file tests/requirements.txt
            --file tests/requirements-s3.txt
            --file tests/requirements-ci.txt
          && pip install -e .

      - name: Show Info
        run: |
          conda info --verbose
          conda list --show-channel-urls

      - name: Run Tests
        run: pytest
          --alluredir="${{ env.ALLURE_DIR }}"
          --basetemp="${{ runner.temp }}/${{ matrix.test-type }}"
          --cov=conda
          --durations-path=tools/durations/${{ runner.os }}.json
          --group=${{ matrix.test-group }}
          --splits=${{ env.PYTEST_SPLITS }}
          -m "${{ env.PYTEST_MARKER }}"
          -n "${{ env.PYTEST_NUMPROCESSES }}"

      - name: Upload Coverage
        uses: codecov/codecov-action@v3
        with:
          flags: ${{ runner.os }},${{ runner.arch }},${{ matrix.python-version }},${{ matrix.test-type }}

      - name: Upload Test Results
        if: '!cancelled()'
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ env.HASH }}
          path: |
            .coverage
            tools/durations/${{ runner.os }}.json
            test-report.xml
          retention-days: 1  # temporary, combined in aggregate below

      - name: Tar Allure
        if: '!cancelled()'
        run: tar -zcf "${{ env.ALLURE_DIR }}.tar.gz" "${{ env.ALLURE_DIR }}"

      - name: Upload Allure
        if: '!cancelled()'
        uses: actions/upload-artifact@v3
        with:
          name: allure-${{ env.HASH }}
          path: ${{ env.ALLURE_DIR }}

  # aggregate and upload
  aggregate:
    # only aggregate test suite if there are code changes
    needs: [changes, windows, linux, linux-qemu, macos]
    if: >-
      !cancelled()
      && needs.changes.outputs.code == 'true'

    runs-on: ubuntu-latest
    steps:
      - name: Download Artifacts
        uses: actions/download-artifact@v3

      - name: Upload Combined Test Results
        # provides one downloadable archive of all matrix run test results for further analysis
        uses: actions/upload-artifact@v3
        with:
          name: test-results-${{ github.sha }}-all
          path: test-results-*
          retention-days: 7  # for durations.yml workflow

      - name: Test Summary
        uses: test-summary/action@v2
        with:
          paths: test-results-*/test-report.xml

  # required check
  analyze:
    name: Analyze results
    needs: [windows, linux, linux-qemu, macos, aggregate]
    if: '!cancelled()'

    runs-on: ubuntu-latest
    steps:
      - name: Determine Success
        uses: re-actors/alls-green@v1.2.2
        with:
          allowed-skips: ${{ toJSON(needs) }}
          jobs: ${{ toJSON(needs) }}

  # canary builds
  build:
    name: Canary Build
    needs: [analyze]
    # only build canary build if
    # - prior steps succeeded,
    # - this is the main repo, and
    # - we are on the main, feature, or release branch
    if: >-
      !cancelled()
      && !github.event.repository.fork
      && (
        github.ref_name == 'main'
        || startsWith(github.ref_name, 'feature/')
        || endsWith(github.ref_name, '.x')
      )
    strategy:
      matrix:
        include:
          - runner: ubuntu-latest
            subdir: linux-64
          - runner: macos-latest
            subdir: osx-64
          - runner: windows-latest
            subdir: win-64
    runs-on: ${{ matrix.runner }}
    steps:
      # Clean checkout of specific git ref needed for package metadata version
      # which needs env vars GIT_DESCRIBE_TAG and GIT_BUILD_STR:
      - uses: actions/checkout@v4
        with:
          ref: ${{ github.ref }}
          clean: true
          fetch-depth: 0

      # Explicitly use Python 3.11 since each of the OSes has a different default Python
      - uses: actions/setup-python@v4
        with:
          python-version: '3.11'

      - name: Detect label
        shell: python
        run: |
          from pathlib import Path
          from re import match
          from os import environ

          if "${{ github.ref_name }}" == "main":
              # main branch commits are uploaded to the dev label
              label = "dev"
          elif "${{ github.ref_name }}".startswith("feature/"):
              # feature branch commits are uploaded to a custom label
              label = "${{ github.ref_name }}"
          else:
              # release branch commits are added to the rc label
              # see https://github.com/conda/infrastructure/issues/760
              _, name = "${{ github.repository }}".split("/")
              label = f"rc-{name}-${{ github.ref_name }}"

          Path(environ["GITHUB_ENV"]).write_text(f"ANACONDA_ORG_LABEL={label}")

      - name: Create and upload canary build
        uses: conda/actions/canary-release@v23.7.0
        env:
          # Run conda-build in isolated activation to properly package conda
          _CONDA_BUILD_ISOLATED_ACTIVATION: 1
        with:
          package-name: ${{ github.event.repository.name }}
          subdir: ${{ matrix.subdir }}
          anaconda-org-channel: conda-canary
          anaconda-org-label: ${{ env.ANACONDA_ORG_LABEL }}
          anaconda-org-token: ${{ secrets.ANACONDA_ORG_CONDA_CANARY_TOKEN }}
